{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15cd239-89ce-42b7-9c96-372b7f37b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Analytics\n",
    "# 1. Extract Sample document and apply following document preprocessing methods:\n",
    "# Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "# 2. Create representation of document by calculating Term Frequency and Inverse Document Frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add6f371-2d6d-4971-bc44-fc4a4d6e7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc1f69a-b36d-4a01-af6f-585d2fd37d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')  #stop word\n",
    "nltk.download('averaged_perceptron_tagger') #pos tagging\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2a6ac3-dc28-422f-a947-4613f851f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample document\n",
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c42f8d93-a755-4fd3-9887-4d5088ce314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829b1d6e-1e98-447c-98ba-3adff8682d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a59ed07-7253-4ded-95f4-f4a9ca5968e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25b9373-fe79-4208-9ed6-8900b7c744ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183aaf9a-d444-4a0b-a56b-e8890363a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "def21f9b-239f-4b35-8acb-fc72a03e3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer= WordNetLemmatizer()\n",
    "lemmatized_token=[lemmatizer.lemmatize(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7187d2ac-aac0-4447-a042-389dc037e93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\", sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8437f586-22cb-4e74-a0a5-1f3ea705ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'The', 'goal', 'is', 'a', 'computer', 'capable', 'of', '``', 'understanding', \"''\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTokenization:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db17e500-0b4b-4a46-82ec-51f9ab68c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS Tagging: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('language', 'NN'), (',', ','), ('in', 'IN'), ('particular', 'JJ'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('computers', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.'), ('The', 'DT'), ('goal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('computer', 'NN'), ('capable', 'NN'), ('of', 'IN'), ('``', '``'), ('understanding', 'JJ'), (\"''\", \"''\"), ('the', 'DT'), ('contents', 'NNS'), ('of', 'IN'), ('documents', 'NNS'), (',', ','), ('including', 'VBG'), ('the', 'DT'), ('contextual', 'JJ'), ('nuances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('within', 'IN'), ('them', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPOS Tagging:\", pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c8d4731-d7e3-47c7-a050-d559a1b38093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop Words Removal: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', ',', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.', 'goal', 'computer', 'capable', '``', 'understanding', \"''\", 'contents', 'documents', ',', 'including', 'contextual', 'nuances', 'language', 'within', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStop Words Removal:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea42fe8-faa6-456f-8563-c54b0936f4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.', 'goal', 'comput', 'capabl', '``', 'understand', \"''\", 'content', 'document', ',', 'includ', 'contextu', 'nuanc', 'languag', 'within', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStemming:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "054a00e8-c050-4eda-bc10-6802cbd34ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', 'language', ',', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', '.', 'goal', 'computer', 'capable', '``', 'understanding', \"''\", 'content', 'document', ',', 'including', 'contextual', 'nuance', 'language', 'within', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLemmatization:\", lemmatized_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084170e-c84e-4cc0-9b13-ef3eafa86dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
